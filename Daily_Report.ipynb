{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9580ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8214185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now()\n",
    "baseurl = 'https://www.smartshanghai.com/housing/apartments-rent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddcf609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "# Function to extract listing IDs posted within the last 24 hours\n",
    "def get_recent_listing_ids():\n",
    "    Listing_id = []\n",
    "    Price = []\n",
    "    N_Bedrooms = []\n",
    "    N_Bathrooms = []\n",
    "    page = 0\n",
    "    while True:\n",
    "        params = {'page': page}\n",
    "        response = requests.get(baseurl, params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            content = soup.find_all(\"div\", class_='cont')\n",
    "            \n",
    "            if not content:  # Stop if there are no more listings\n",
    "                break\n",
    "            \n",
    "            for i in range(len(content)):\n",
    "                listing_time_element = content[i].find('div', class_='address').text.strip()\n",
    "                time_diff = convert_time_indicator(listing_time_element)\n",
    "                \n",
    "                if time_diff <= timedelta(hours=23):\n",
    "                    Listing_id.append(content[i].find('div').attrs['data-listingid'])\n",
    "                    Price.append(''.join(content[i].find('div', class_=\"price\").text.strip().split()[1].split(',')))\n",
    "                    info = re.findall('\\d+', content[i].find('div', class_='room-type').text.strip())\n",
    "                    N_Bedrooms.append(info[1])\n",
    "                    N_Bathrooms.append(info[2])\n",
    "                else:\n",
    "                    # Stop scraping when encountering a listing older than 24 hours\n",
    "                    return pd.DataFrame({'listing_id': Listing_id, 'price': Price, 'N_Bedrooms': N_Bedrooms, 'N_Bathrooms': N_Bathrooms})\n",
    "                \n",
    "            page += 1\n",
    "        else:\n",
    "            print(response.status_code)\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame({'listing_id': Listing_id, 'price': Price, 'N_Bedrooms': N_Bedrooms, 'N_Bathrooms': N_Bathrooms})\n",
    "\n",
    "# Function to convert time indicator to a timedelta\n",
    "def convert_time_indicator(time_str):\n",
    "    if 'hour' in time_str:\n",
    "        hours = int(time_str.split()[0])\n",
    "        return timedelta(hours=hours)\n",
    "    return timedelta()\n",
    "\n",
    "\n",
    "\n",
    "daily_data = get_recent_listing_ids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a501e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "values = []\n",
    "amenities_data = []\n",
    "\n",
    "for list_id in daily_data['listing_id']:\n",
    "    response = requests.get(f'{baseurl}/{list_id}')\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup_info = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Extract the labels and values for the current listing ID\n",
    "        labels = [label.get_text(strip=True)[:-1] for label in soup_info.find_all('div', class_='details')[0].find_all(name='label')]\n",
    "        row_values = [value.get_text(strip=True) for value in soup_info.find_all('div', class_='details')[0].find_all(name='div')[:-1]]\n",
    "        \n",
    "        # Append unique columns to the columns list\n",
    "        columns.extend(label for label in labels if label not in columns)\n",
    "        \n",
    "        # Append values for the current listing ID while maintaining the correct order\n",
    "        row = {}\n",
    "        for label, value in zip(labels, row_values):\n",
    "            row[label] = value\n",
    "        values.append(row)\n",
    "        \n",
    "        # Extract amenities information\n",
    "        amenities = soup_info.find_all('div', class_='amenities')[0].find_all('li', class_=['positive', 'negative'])\n",
    "        amenities_dict = {}\n",
    "        \n",
    "        for amenity_li in amenities:\n",
    "            amenity = amenity_li.text.strip()\n",
    "            amenities_dict[amenity] = 1 if 'positive' in amenity_li['class'] else 0\n",
    "        \n",
    "        amenities_dict['listing_id'] = list_id\n",
    "        amenities_data.append(amenities_dict)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for listing ID: {list_id}\")\n",
    "\n",
    "# Create DataFrames for values and amenities data\n",
    "values_df = pd.DataFrame(values)\n",
    "amenities_df = pd.DataFrame(amenities_data)\n",
    "\n",
    "# Merge the amenities DataFrame with the original DataFrame on 'listing_id'\n",
    "merged_df = pd.merge(daily_data, amenities_df, on='listing_id', how='left')\n",
    "\n",
    "# Concatenate the merged DataFrame with the values DataFrame\n",
    "final_df = pd.concat([merged_df, values_df], axis=1)\n",
    "final_df.columns = final_df.columns.str.replace(\"\\n\", \"\").str.replace(\" \", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Data cleaning\n",
    "final_df.columns = final_df.columns.str.replace(\"\\n\", \"\").str.replace(\" \", \"\")\n",
    "\n",
    "# List of columns to clean\n",
    "columns_to_clean = ['MinimalRentalPeriod', 'DepositRequirement', 'AdvanceRentPayment','AgencyCommission','Size']\n",
    "\n",
    "# Define a function to clean the data in each specified column\n",
    "def clean_column_data(df, column):\n",
    "    df[column] = df[column].str.extract('(\\d+)')\n",
    "\n",
    "# Apply the cleaning operation to each column in the list\n",
    "for column in columns_to_clean:\n",
    "    clean_column_data(final_df, column)\n",
    "\n",
    "final_df['MetroStation'] = final_df['MetroStation'].str.split('to').str[1].str.split('on ').str[0].str.strip()\n",
    "\n",
    "# Keep only 'PetsAllowedtrue' column and rename it to 'PetsAllowed'\n",
    "final_df['PetsAllowed'] = final_df['PetsAllowedtrue']\n",
    "\n",
    "# Drop 'PetsAllowedtrue' column\n",
    "final_df.drop(columns=['PetsAllowedtrue','Rooms'], inplace=True)\n",
    "\n",
    "# Fill NaN values in the 'PetsAllowed' column with 0\n",
    "final_df['PetsAllowed'] = final_df['PetsAllowed'].fillna(0)\n",
    "final_df = final_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(f\"{current_time}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d06783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
